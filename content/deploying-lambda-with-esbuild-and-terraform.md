+++
title = "Deploying Lambda with ESBuild and Terraform"
slug = "deploying-lambda-with-esbuild-and-terraform"
date = "2022-03-10"
category = "serverless"

[extra]
author = "Bob Gregory"

[taxonomies]
tags = ["serverless", "typescript", "terraform"]
+++

Generally when deploying Lambda functions, I use the [Serverless Framework](). This is a wrapper around AWS Cloudformation that makes it easier for engineers to author and deploy code. It's much easier to get started when using an abstraction like this, but sometimes we need to drop down and work at a lower-level. 

I recently needed to deploy a lambda function with a large number of triggers, and the cloudformation template generated by the serverless framework was too large to deploy. Instead I ended up configuring everything in plain Terraform. There are a few moving pieces to understand, but in return for some more overhead, we gain a lot of flexibility. In this post I want to show you how to configure and deploy a simple lambda function, confguring everything ourselves in Terraform so we can see how it all fits together.

## What are we going to create?

We're going to build a simple lambda function that wakes up every day at 9am and checks stock prices for a small list of companies, then stashes the result in Dynamo. We'll configure Amazon EventBridge to raise an event on a schedule - like a cron job - and we'll use the event to trigger our Lambda function.

![Picture goes here, yo]()

## Starting with the handler

Our handler code is simple, but we take care to make sure our code is testable. There are two steps to our process:

1. Fetch the most recent prices from the API and
2. Persist them to a table.

We can treat each of these as a separate component in our code: the PriceFetcher and the PricePersister. The main body of our code looks like this:

```typescript
export const updatePrices = async (
  fetcher: PriceFetcher,
  persister: PricePersister,
  symbols: Array<string>
) => {
  // fetch the prices with a fetcher
  const prices = await fetcher.fetch(symbols);
  // and persist them with a persister
  await persister.save(prices);
};
```

Structuring the code this way means that we can test each part of the code in isolation: I can use a mocked API with a real dynamo table, or a fake dynamo table with a real API, or use real implementations for both.

We can wrap this code in a lambda function that provides real implementations for our components

```
const handler: EventBridgeHandler<
  "Scheduled Event",
  Empty,
  void
> = async () => {
  const client = new DynamoDB.DocumentClient();
  await updatePrices(
    new PriceFetcherImpl(config().apiToken),
    new PricePersisterImpl(config().dynamoTable, client),
    ["AAPL", "GOOG"]
  );
};
```

This handler doesn't have any logic, it's just wiring up the dependencies and invoking our `updatePrices` function. That means we can concentrate our testing on the function, which is easy to configure, and forget about testing the lambda itself which is _boring_ code.

Aside: This is the [composition root](https://freecontent.manning.com/dependency-injection-in-net-2nd-edition-understanding-the-composition-root/) pattern. It lets us keep all our dependency injection in a single place, so that we can mock out dependencies for testing without relying on [magic](https://jestjs.io/docs/mock-functions)

## Packaging the handler

To deploy our lambda function, we'll need to bundle it up and turn it into a zip file. We're using esbuild, which means that bundling is a one liner:

```
 esbuild \
    --bundle src/handler.ts \
    --target=node14 \
    --format=cjs \
    --external:aws-sdk \
    --outfile=build/index.js`
```

Line by line, we want to bundle the handler, targeting Node 14 (the latest supported version for Lambda), into a commonjs module. We don't want to bundle the AWS-SDK because that would make our code much larger, and it's already available in the lambda runtime, and we'll create the file `index.js`.

  * [ ] 
 
